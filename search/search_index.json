{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Rhea","text":"<p>A scalable MCP (Model Context Protocol) tool framework to serve thousands of biomedical tools for Large Language Models.</p> <p>Example executions with Claude:</p> <ul> <li>A multi-step conversion from FASTA -&gt; FASTQ -&gt; CSV</li> <li>A simple CSV to Tabular conversion</li> </ul>"},{"location":"#how-it-works","title":"How it works?","text":"<p>The MCP server first provides a single tool, <code>find_tools</code> which accepts a natural language query to select relevant tools. For example, an LLM (or user) can provide a query of \"I need a tool to convert a CSV file to tabular.\", which the server will then perform a RAG on a collection of tools to populate the server with <code>n</code> most relevant tools to the query. Once the server is populated, the LLM/user will have access to those relevant tools, along with their parameter annotations and documentations.</p> <p>To provide file inputs/outputs with the tool agents, we utilize ProxyStore with a Redis backend, providing keys to the tool when a file input is required. </p> <p>When a tool is called, the server utilizes Parsl to spawn an Academy agent that creates an environment for the tool, installing necessary requirements and pulling program files from a S3 object store. The agent will be provided the arguments provided by the MCP server, and return its stdout/stderr along with any output files as ProxyStore keys.</p>"},{"location":"#setup","title":"Setup","text":""},{"location":"#requirements","title":"Requirements","text":"<ul> <li><code>uv</code> - Package manager for Python projects.</li> <li><code>docker</code> - To run tools locally (external executor comming soon!)</li> </ul> <p>Additionally, the server will need to point to an existing OpenAI-like endpoint (for embedding), Postgres, Redis, and MinIO server. Documentation coming soon.</p>"},{"location":"#instalation","title":"Instalation","text":"<p>After cloning the repository, use <code>uv</code> to configure the virtual environment. </p> <pre><code>uv sync\n</code></pre>"},{"location":"#configuring-environment","title":"Configuring Environment","text":"<p>An example <code>.env</code> file is provided in <code>.env.example</code>. Datasets coming soon!</p>"},{"location":"#installing-into-claude-desktop","title":"Installing into Claude Desktop","text":"<p>In your <code>claude_desktop_config.json</code> file, add the following entry (Make sure to replace <code>location_of_repo</code> with the actual location!):</p>"},{"location":"#macoslinux","title":"macOS/Linux","text":"<pre><code>{\n  \"mcpServers\": {\n    \"Rhea\": {\n        \"command\": \"bash\",\n        \"args\": [\n            \"-lc\",\n            \"cd location_of_repo &amp;&amp; uv run -m server.mcp_server\"\n        ]\n    }\n  }\n}\n</code></pre>"},{"location":"#windows-wsl","title":"Windows (WSL)","text":"<pre><code>{\n  \"mcpServers\": {\n    \"Rhea\": {\n        \"command\": \"wsl.exe\",\n        \"args\": [\n            \"bash\",\n            \"-lc\",\n            \"cd location_of_repo &amp;&amp; uv run -m server.mcp_server\"\n        ]\n    }\n  }\n}\n</code></pre>"},{"location":"#testing-with-mcp-inspector","title":"Testing with MCP Inspector","text":"<p>To test the tools with MCP Inspector:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>And set the following configuration parameters:</p> Parameter Value Transport Type STDIO Command uv Arguments run -m server.mcp_server Request Timeout 600000 Reset Timeouts on Progress True Maximum Total Timeout 600000 Proxy Session Token Token provided within CLI <p>Note: The timeouts are a temporary workaround to make sure the MCP client does not timeout during long tool executions. Better progress reporting is coming soon.</p>"},{"location":"#running-with-sse-transport","title":"Running with SSE Transport","text":"<p>By default, the MCP server will start with STDIO transport for use with Claude Desktop. To enable SSE transport layer:</p> <pre><code>uv run -m server.mcp_server --transport sse\n</code></pre>"},{"location":"#running-with-streamable-http","title":"Running with Streamable HTTP","text":"<p>Work in progress!</p>"},{"location":"client/","title":"Client Python Library","text":"<p>The Rhea client Python library allows you to interact with the Rhea MCP server similar to the FastMCP client library.</p> <p>The client library utilizes both MCP and REST protocols of the Rhea server to allow for MCP tool calling and REST API file handling.</p> <p>See examples on how to use the Client library.</p>"},{"location":"client/#client.RheaClient","title":"<code>RheaClient(hostname: str, port: int, secure: bool = False)</code>","text":"<p>               Bases: <code>RheaMCPClientBase</code>, <code>RheaRESTClientBase</code></p> <p>A client class to interact with both the Rhea Model Context Protocol (MCP) server and REST backend.</p> <p>The client class provides similar high-level interface to the one found within the Python MCP SDK.</p> <p>The class also provides additional utilities to interact with the REST backend such as file upload and downloads.</p> <p>Example: <pre><code>async with RheaClient('localhost', 3001) as client:\n    # MCP call\n    tools = await client.find_tools('I need a tool to convert FASTA to FASTQ')\n    # REST call\n    key = await client.upload_file('test.txt')\n</code></pre></p> Source code in <code>client/__init__.py</code> <pre><code>def __init__(self, hostname: str, port: int, secure: bool = False):\n    self._hostname = hostname\n    self._port = port\n    self._secure = secure\n\n    self._mcp_ctx: Optional[RheaMCPClient] = None\n    self._mcp_client: Optional[RheaMCPClient] = None\n\n    self._rest_ctx: Optional[RheaRESTClient] = None\n    self._rest_client: Optional[RheaRESTClient] = None\n</code></pre>"},{"location":"client/#client.RheaClient.list_tools","title":"<code>list_tools() -&gt; list[Tool]</code>  <code>async</code>","text":"<p>List the currently available tools on the server for this session.</p> <p>Returns:</p> Type Description <code>list[Tool]</code> <p>list[Tool]: A list of MCP tool definitions.</p> Source code in <code>client/__init__.py</code> <pre><code>async def list_tools(self) -&gt; list[Tool]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.list_tools()\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.find_tools","title":"<code>find_tools(query: str) -&gt; list[dict]</code>  <code>async</code>","text":"<p>Find available tools on the MCP server that match the query.</p> <p>This method searches for tools matching the provided query string and returns their descriptions.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query to find relevant tools.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of tool descriptions matching the query.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def find_tools(self, query: str) -&gt; list[dict]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.find_tools(query)\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.call_tool","title":"<code>call_tool(name: str, arguments: dict[str, Any]) -&gt; dict | None</code>  <code>async</code>","text":"<p>Call a specific tool on the MCP server with the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the tool to call.</p> required <code>arguments</code> <code>dict[str, Any]</code> <p>The arguments to pass to the tool.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: The structured content of the tool's response,          or None if there is no structured content.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def call_tool(self, name: str, arguments: dict[str, Any]) -&gt; dict | None:\n    if self._mcp_client is not None:\n        return await self._mcp_client.call_tool(name, arguments)\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.list_resources","title":"<code>list_resources() -&gt; list[Resource]</code>  <code>async</code>","text":"<p>List all available resources from the Rhea MCP server.</p> <p>This asynchronous method retrieves a list of all resources accessible through the initialized Rhea client. The client must have an active session before calling this method.</p> <p>Returns:</p> Name Type Description <code>ListResourcesResult</code> <code>list[Resource]</code> <p>A result object containing the list of available resources.</p> <p>Raises:     RuntimeError: If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def list_resources(self) -&gt; list[Resource]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.list_resources()\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.read_resource","title":"<code>read_resource(uri: AnyUrl) -&gt; list[TextResourceContents | BlobResourceContents]</code>  <code>async</code>","text":"<p>Read a specific resource from the Rhea MCP server by its URI.</p> <p>This method retrieves the contents of a resource identified by the provided URI. The resource contents can be either text or binary data.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>AnyUrl</code> <p>The URI of the resource to read.</p> required <p>Returns:</p> Type Description <code>list[TextResourceContents | BlobResourceContents]</code> <p>list[TextResourceContents | BlobResourceContents]: A list of resource contents, which can be either text or binary data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def read_resource(\n    self, uri: AnyUrl\n) -&gt; list[TextResourceContents | BlobResourceContents]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.read_resource(uri)\n    raise RuntimeError(\"`mcp_clien` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.upload_file","title":"<code>upload_file(path: str, name: str | None = None, timeout: int = 300, chunk_size: int = 1 &lt;&lt; 20) -&gt; dict</code>  <code>async</code>","text":"<p>Upload a file from local directory to Rhea MCP server.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of local file to upload.</p> required <code>name</code> <code>str</code> <p>Optional filename to use on the server side. Defaults to source filename.</p> <code>None</code> <code>timeout</code> <code>int</code> <p>Request timeout in seconds. Defaults to <code>300</code> seconds.</p> <code>300</code> <code>chunk_size</code> <code>int</code> <p>Chunk size to read and upload file. Defaults to 1MB.</p> <code>1 &lt;&lt; 20</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Server response</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def upload_file(\n    self,\n    path: str,\n    name: str | None = None,\n    timeout: int = 300,\n    chunk_size: int = 1 &lt;&lt; 20,\n) -&gt; dict:\n    if self._rest_client is not None:\n        return await self._rest_client.upload_file(path, name, timeout, chunk_size)\n    raise RuntimeError(\"`rest_client` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.download_file","title":"<code>download_file(key: str, output_directory: Path = Path.cwd(), timeout: int = 300, chunk_size: int = 1 &lt;&lt; 20) -&gt; int</code>  <code>async</code>","text":"<p>Download a file to local directory from Rhea MCP server.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>File key of desired file to download.</p> required <code>output_directory</code> <code>Path</code> <p>Output directory to write to. Defaults to current working directory.</p> <code>cwd()</code> <code>timeout</code> <code>int</code> <p>Request timeout in seconds. Defaults to <code>300</code> seconds.</p> <code>300</code> <code>chunk_size</code> <code>int</code> <p>Chunk size for download stream. Defaults to 1MB.</p> <code>1 &lt;&lt; 20</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Size of downloaded file in bytes.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def download_file(\n    self,\n    key: str,\n    output_directory: Path = Path.cwd(),\n    timeout: int = 300,\n    chunk_size: int = 1 &lt;&lt; 20,\n) -&gt; int:\n    if self._rest_client is not None:\n        return await self._rest_client.download_file(\n            key, output_directory, timeout, chunk_size\n        )\n    raise RuntimeError(\"`rest_client` is None\")\n</code></pre>"},{"location":"client/#client.RheaClient.metrics","title":"<code>metrics() -&gt; dict[str, list[dict]]</code>  <code>async</code>","text":"<p>Get Prometheus metrics from Rhea MCP server.</p> <p>See: Prometheus Specification</p> <p>Returns:</p> Type Description <code>dict[str, list[dict]]</code> <p>dict[str, list[dict]]: Server metrics</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>client/__init__.py</code> <pre><code>async def metrics(self) -&gt; dict[str, list[dict]]:\n    if self._rest_client is not None:\n        return await self._rest_client.metrics()\n    raise RuntimeError(\"`rest_client` is None\")\n</code></pre>"},{"location":"deploy/","title":"Deploying Rhea","text":""},{"location":"deploy/#docker-local","title":"Docker (Local)","text":"<pre><code>docker compose -f deploy/docker-compose.yaml up -d\n</code></pre> <p>With GPU support (for embedding model):</p> <pre><code>docker compose -f deploy/docker-compose.gpu.yaml -d\n</code></pre>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#file-management","title":"File management","text":"<p>For many tools, you will need to manage input and output files for your tool calls. </p> <p>Files are keyed as UUIDv4 strings and are accepted as input for tool calls requiring input files. </p>"},{"location":"examples/#uploading-a-file","title":"Uploading a file","text":"<p>The following script lets you upload a file from your local directory to the Rhea MCP server. </p> <p>The script will output a UUIDv4 string representing the file string.</p> <p>This script can be found in examples/upload_file.py</p> <pre><code># upload_file.py\n\nimport asyncio\nfrom client import RheaClient\nfrom argparse import ArgumentParser\nfrom urllib.parse import urlparse\n\nparser = ArgumentParser(description=\"Upload files to Rhea MCP server\")\nparser.add_argument(\"input_file\", help=\"Input file\")\nparser.add_argument(\"--url\", help=\"URL of MCP server\", default=\"http://localhost:3001\")\nparser.add_argument(\"--name\", required=False, help=\"Name for uploaded file.\")\n\nargs = parser.parse_args()\n\n\nasync def main():\n    parsed_url = urlparse(args.url)\n    protocol = parsed_url.scheme\n    host = parsed_url.hostname\n    port = parsed_url.port\n    secure = protocol == \"https\"\n\n    async with RheaClient(host, port, secure) as client:  # (1)!\n        result: dict = await client.upload_file(args.input_file, args.name)  # (2)!\n        print(result)\n        print(result[\"key\"])  # (3)!\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())  # (4)!\n</code></pre> <ol> <li>Open a connection with the MCP server with an asynchronous context manager.</li> <li>Call <code>upload_file()</code> with the path of your file.</li> <li>This is the file key for your uploaded file to be used as input for tools.</li> <li>Make sure to run as a coroutine.</li> </ol> <p>Usage: <pre><code>python upload_file.py /path/to/file --url http://localhost:3001\n</code></pre></p>"},{"location":"examples/#downloading-a-file","title":"Downloading a file","text":"<p>The following scripts lets you download a file from the Rhea MCP server to a local directory.</p> <p>This script can be found in examples/download_file.py</p> <pre><code># download_file.py\n\nimport asyncio\nfrom client import RheaClient\nfrom argparse import ArgumentParser\nfrom pathlib import Path\nfrom urllib.parse import urlparse\n\nparser = ArgumentParser(description=\"Download files from Rhea MCP server\")\nparser.add_argument(\"key\", help=\"Key of desired file\")\nparser.add_argument(\"--url\", help=\"URL of MCP server\", default=\"http://localhost:3001\")\nparser.add_argument(\"--output-directory\", help=\"Output directory\", default=Path.cwd())\nparser.add_argument(\"--output-name\", help=\"Name of output file\")\n\nargs = parser.parse_args()\n\n\nasync def main():\n    parsed_url = urlparse(args.url)\n    protocol = parsed_url.scheme\n    host = parsed_url.hostname\n    port = parsed_url.port\n    secure = protocol == \"https\"\n\n    async with RheaClient(host, port, secure) as client:  # (1)!\n        await client.download_file(args.key, args.output_directory)  # (2)!\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())  # (3)!\n</code></pre> <ol> <li>Open a connection with the MCP server with an asynchronous context manager. </li> <li>Call <code>download_file()</code> with your desired file key and output path.</li> <li>Make sure to run as a coroutine.</li> </ol> <p>Usage: <pre><code>python download_file.py file_key /path/to/output/directory\n</code></pre></p>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#architecture","title":"Architecture","text":""},{"location":"overview/#protocol","title":"Protocol","text":"<pre><code>sequenceDiagram\nparticipant Client as Client\nparticipant Server as Server\n\nNote over Client, Server: Initialization\nClient-&gt;&gt;Server: Call tools/list\nServer-&gt;&gt;Client: Return find_tools()\n\nloop Agent Loop\nNote over Client, Server: Perform Tool Discovery (RAG)\nClient-&gt;&gt;Server: Call find_tools(query)\nServer--&gt;&gt;Client: Notify tools/list_changed\nClient-&gt;&gt;Server: Get tools/list\nServer--&gt;&gt;Client: List of tools\n\n\nNote over Client, Server: Call Tool\nClient-&gt;&gt;Server: Call Tool echo('hello')\nServer--&gt;&gt;Client: Tool Progress (0%)\nServer--&gt;&gt;Client: Tool Progress (100%)\nServer-&gt;&gt;Client: Return result for Tool echo('hello')\n\nend\n</code></pre>"}]}