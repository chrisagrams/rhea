{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Rhea","text":"<p>A scalable MCP (Model Context Protocol) tool framework to serve thousands of biomedical tools for Large Language Models.</p> <p>Example executions with Claude:</p> <ul> <li>A multi-step conversion from FASTA -&gt; FASTQ -&gt; CSV</li> <li>A simple CSV to Tabular conversion</li> </ul>"},{"location":"#how-it-works","title":"How it works?","text":"<p>The MCP server first provides a single tool, <code>find_tools</code> which accepts a natural language query to select relevant tools. For example, an LLM (or user) can provide a query of \"I need a tool to convert a CSV file to tabular.\", which the server will then perform a RAG on a collection of tools to populate the server with <code>n</code> most relevant tools to the query. Once the server is populated, the LLM/user will have access to those relevant tools, along with their parameter annotations and documentations.</p> <p>To provide file inputs/outputs with the tool agents, we utilize ProxyStore with a Redis backend, providing keys to the tool when a file input is required. </p> <p>When a tool is called, the server utilizes Parsl to spawn an Academy agent that creates an environment for the tool, installing necessary requirements and pulling program files from a S3 object store. The agent will be provided the arguments provided by the MCP server, and return its stdout/stderr along with any output files as ProxyStore keys.</p>"},{"location":"#setup","title":"Setup","text":""},{"location":"#requirements","title":"Requirements","text":"<ul> <li><code>uv</code> - Package manager for Python projects.</li> <li><code>docker</code> - To run tools locally (external executor comming soon!)</li> </ul> <p>Additionally, the server will need to point to an existing OpenAI-like endpoint (for embedding), Postgres, Redis, and MinIO server. Documentation coming soon.</p>"},{"location":"#instalation","title":"Instalation","text":"<p>After cloning the repository, use <code>uv</code> to configure the virtual environment. </p> <pre><code>uv sync\n</code></pre>"},{"location":"#configuring-environment","title":"Configuring Environment","text":"<p>An example <code>.env</code> file is provided in <code>.env.example</code>. Datasets coming soon!</p>"},{"location":"#installing-into-claude-desktop","title":"Installing into Claude Desktop","text":"<p>In your <code>claude_desktop_config.json</code> file, add the following entry (Make sure to replace <code>location_of_repo</code> with the actual location!):</p>"},{"location":"#macoslinux","title":"macOS/Linux","text":"<pre><code>{\n  \"mcpServers\": {\n    \"Rhea\": {\n        \"command\": \"bash\",\n        \"args\": [\n            \"-lc\",\n            \"cd location_of_repo &amp;&amp; uv run -m server.mcp_server\"\n        ]\n    }\n  }\n}\n</code></pre>"},{"location":"#windows-wsl","title":"Windows (WSL)","text":"<pre><code>{\n  \"mcpServers\": {\n    \"Rhea\": {\n        \"command\": \"wsl.exe\",\n        \"args\": [\n            \"bash\",\n            \"-lc\",\n            \"cd location_of_repo &amp;&amp; uv run -m server.mcp_server\"\n        ]\n    }\n  }\n}\n</code></pre>"},{"location":"#testing-with-mcp-inspector","title":"Testing with MCP Inspector","text":"<p>To test the tools with MCP Inspector:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>And set the following configuration parameters:</p> Parameter Value Transport Type STDIO Command uv Arguments run -m server.mcp_server Request Timeout 600000 Reset Timeouts on Progress True Maximum Total Timeout 600000 Proxy Session Token Token provided within CLI <p>Note: The timeouts are a temporary workaround to make sure the MCP client does not timeout during long tool executions. Better progress reporting is coming soon.</p>"},{"location":"#running-with-sse-transport","title":"Running with SSE Transport","text":"<p>By default, the MCP server will start with STDIO transport for use with Claude Desktop. To enable SSE transport layer:</p> <pre><code>uv run -m rhea.server.mcp_server --transport sse\n</code></pre>"},{"location":"#running-with-streamable-http","title":"Running with Streamable HTTP","text":"<p>Work in progress!</p>"},{"location":"client/","title":"Client Python Library","text":"<p>The Rhea client Python library allows you to interact with the Rhea MCP server similar to the FastMCP client library.</p> <p>The client library utilizes both MCP and REST protocols of the Rhea server to allow for MCP tool calling and REST API file handling.</p> <p>See examples on how to use the Client library.</p>"},{"location":"client/#rhea.client.RheaClient","title":"<code>RheaClient(hostname: str, port: int, secure: bool = False)</code>","text":"<p>               Bases: <code>RheaMCPClientBase</code>, <code>RheaRESTClientBase</code></p> <p>A client class to interact with both the Rhea Model Context Protocol (MCP) server and REST backend.</p> <p>The client class provides similar high-level interface to the one found within the Python MCP SDK.</p> <p>The class also provides additional utilities to interact with the REST backend such as file upload and downloads.</p> <p>Example: <pre><code>async with RheaClient('localhost', 3001) as client:\n    # MCP call\n    tools = await client.find_tools('I need a tool to convert FASTA to FASTQ')\n    # REST call\n    key = await client.upload_file('test.txt')\n</code></pre></p> Source code in <code>rhea/client/__init__.py</code> <pre><code>def __init__(self, hostname: str, port: int, secure: bool = False):\n    self._hostname = hostname\n    self._port = port\n    self._secure = secure\n\n    self._mcp_ctx: Optional[RheaMCPClient] = None\n    self._mcp_client: Optional[RheaMCPClient] = None\n\n    self._rest_ctx: Optional[RheaRESTClient] = None\n    self._rest_client: Optional[RheaRESTClient] = None\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.list_tools","title":"<code>list_tools() -&gt; list[Tool]</code>  <code>async</code>","text":"<p>List the currently available tools on the server for this session.</p> <p>Returns:</p> Type Description <code>list[Tool]</code> <p>list[Tool]: A list of MCP tool definitions.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def list_tools(self) -&gt; list[Tool]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.list_tools()\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.find_tools","title":"<code>find_tools(query: str) -&gt; list[dict]</code>  <code>async</code>","text":"<p>Find available tools on the MCP server that match the query.</p> <p>This method searches for tools matching the provided query string and returns their descriptions.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query to find relevant tools.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of tool descriptions matching the query.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def find_tools(self, query: str) -&gt; list[dict]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.find_tools(query)\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.call_tool","title":"<code>call_tool(name: str, arguments: dict[str, Any]) -&gt; dict | None</code>  <code>async</code>","text":"<p>Call a specific tool on the MCP server with the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the tool to call.</p> required <code>arguments</code> <code>dict[str, Any]</code> <p>The arguments to pass to the tool.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: The structured content of the tool's response,          or None if there is no structured content.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def call_tool(self, name: str, arguments: dict[str, Any]) -&gt; dict | None:\n    if self._mcp_client is not None:\n        return await self._mcp_client.call_tool(name, arguments)\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.list_resources","title":"<code>list_resources() -&gt; list[Resource]</code>  <code>async</code>","text":"<p>List all available resources from the Rhea MCP server.</p> <p>This asynchronous method retrieves a list of all resources accessible through the initialized Rhea client. The client must have an active session before calling this method.</p> <p>Returns:</p> Name Type Description <code>ListResourcesResult</code> <code>list[Resource]</code> <p>A result object containing the list of available resources.</p> <p>Raises:     RuntimeError: If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def list_resources(self) -&gt; list[Resource]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.list_resources()\n    raise RuntimeError(\"`mcp_client` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.read_resource","title":"<code>read_resource(uri: AnyUrl) -&gt; list[TextResourceContents | BlobResourceContents]</code>  <code>async</code>","text":"<p>Read a specific resource from the Rhea MCP server by its URI.</p> <p>This method retrieves the contents of a resource identified by the provided URI. The resource contents can be either text or binary data.</p> <p>Parameters:</p> Name Type Description Default <code>uri</code> <code>AnyUrl</code> <p>The URI of the resource to read.</p> required <p>Returns:</p> Type Description <code>list[TextResourceContents | BlobResourceContents]</code> <p>list[TextResourceContents | BlobResourceContents]: A list of resource contents, which can be either text or binary data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def read_resource(\n    self, uri: AnyUrl\n) -&gt; list[TextResourceContents | BlobResourceContents]:\n    if self._mcp_client is not None:\n        return await self._mcp_client.read_resource(uri)\n    raise RuntimeError(\"`mcp_clien` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.upload_file","title":"<code>upload_file(path: str, name: str | None = None, timeout: int = 300, chunk_size: int = 1 &lt;&lt; 20) -&gt; dict</code>  <code>async</code>","text":"<p>Upload a file from local directory to Rhea MCP server.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of local file to upload.</p> required <code>name</code> <code>str</code> <p>Optional filename to use on the server side. Defaults to source filename.</p> <code>None</code> <code>timeout</code> <code>int</code> <p>Request timeout in seconds. Defaults to <code>300</code> seconds.</p> <code>300</code> <code>chunk_size</code> <code>int</code> <p>Chunk size to read and upload file. Defaults to 1MB.</p> <code>1 &lt;&lt; 20</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Server response</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def upload_file(\n    self,\n    path: str,\n    name: str | None = None,\n    timeout: int = 300,\n    chunk_size: int = 1 &lt;&lt; 20,\n) -&gt; dict:\n    if self._rest_client is not None:\n        return await self._rest_client.upload_file(path, name, timeout, chunk_size)\n    raise RuntimeError(\"`rest_client` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.download_file","title":"<code>download_file(key: str, output_directory: Path = Path.cwd(), timeout: int = 300, chunk_size: int = 1 &lt;&lt; 20) -&gt; int</code>  <code>async</code>","text":"<p>Download a file to local directory from Rhea MCP server.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>File key of desired file to download.</p> required <code>output_directory</code> <code>Path</code> <p>Output directory to write to. Defaults to current working directory.</p> <code>cwd()</code> <code>timeout</code> <code>int</code> <p>Request timeout in seconds. Defaults to <code>300</code> seconds.</p> <code>300</code> <code>chunk_size</code> <code>int</code> <p>Chunk size for download stream. Defaults to 1MB.</p> <code>1 &lt;&lt; 20</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Size of downloaded file in bytes.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def download_file(\n    self,\n    key: str,\n    output_directory: Path = Path.cwd(),\n    timeout: int = 300,\n    chunk_size: int = 1 &lt;&lt; 20,\n) -&gt; int:\n    if self._rest_client is not None:\n        return await self._rest_client.download_file(\n            key, output_directory, timeout, chunk_size\n        )\n    raise RuntimeError(\"`rest_client` is None\")\n</code></pre>"},{"location":"client/#rhea.client.RheaClient.metrics","title":"<code>metrics() -&gt; dict[str, list[dict]]</code>  <code>async</code>","text":"<p>Get Prometheus metrics from Rhea MCP server.</p> <p>See: Prometheus Specification</p> <p>Returns:</p> Type Description <code>dict[str, list[dict]]</code> <p>dict[str, list[dict]]: Server metrics</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the client session fails to initialize or used outside of a context manager.</p> Source code in <code>rhea/client/__init__.py</code> <pre><code>async def metrics(self) -&gt; dict[str, list[dict]]:\n    if self._rest_client is not None:\n        return await self._rest_client.metrics()\n    raise RuntimeError(\"`rest_client` is None\")\n</code></pre>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#rhea.server.schema.Settings","title":"<code>Settings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Base settings class for Rhea server.</p> <p>Attributes:</p> Name Type Description <code>host</code> <code>str</code> <p>Host interface to listen on. Defaults to <code>localhost</code>.</p> <code>port</code> <code>int</code> <p>Port number to listen on. Defaults to <code>3001</code>.</p> <code>debug_port</code> <code>int</code> <p>Optionally specify port to enable debugpy.</p> <code>database_url</code> <code>str</code> <p>URL to Postgres database. Defaults to <code>postgresql+asyncpg://postgres:postgres@localhost:5432/rhea</code>.</p> <code>client_ttl</code> <code>int</code> <p>Time to maintain client state before flushing. Defaults to <code>3600</code> seconds.</p> <code>parsl_container_backend</code> <code>Literal['docker', 'podman']</code> <p>Specify which container engine to use (Docker or Podman). Defaults to <code>docker</code>.</p> <code>parsl_container_network</code> <code>Literal['host', 'local']</code> <p>Specify container networking. Defaults to <code>host</code>.</p> <code>parsl_container_debug</code> <code>bool</code> <p>Whether to enable debugging port inside container. Defaults to <code>False</code>.</p> <code>parsl_max_workers_per_node</code> <code>int</code> <p>Maximum number of workers per node for Parsl execution. Defaults to <code>1</code>.</p> <code>parsl_provider</code> <code>Literal['local', 'pbs', 'k8']</code> <p>Parsl execution provider type. Defaults to <code>local</code>.</p> <code>parsl_init_blocks</code> <code>int</code> <p>Initial number of blocks to provision. Defaults to <code>0</code>.</p> <code>parsl_min_blocks</code> <code>int</code> <p>Minimum number of blocks to maintain. Defaults to <code>0</code>.</p> <code>parsl_max_blocks</code> <code>int</code> <p>Maximum number of blocks allowed. Defaults to <code>5</code>.</p> <code>parsl_nodes_per_block</code> <code>int</code> <p>Number of nodes per block. Defaults to <code>1</code>.</p> <code>parsl_parallelism</code> <code>int</code> <p>Level of parallelism for Parsl execution. Defaults to <code>1</code>.</p> <code>agent_handle_timeout</code> <code>int</code> <p>Time to wait to retrieve handle from agent in seconds. Defaults to <code>30</code>.</p> <code>redis_host</code> <code>str</code> <p>Redis server host address. Defaults to <code>localhost</code>.</p> <code>redis_port</code> <code>int</code> <p>Redis server port number. Defaults to <code>6379</code>.</p> <code>embedding_url</code> <code>str</code> <p>URL endpoint for embedding service. Defaults to <code>http://localhost:8000/v1</code>.</p> <code>embedding_key</code> <code>str</code> <p>API key for embedding service. Defaults to empty string.</p> <code>model</code> <code>str</code> <p>Embedding model to use. Defaults to <code>Qwen/Qwen3-Embedding-0.6B</code>.</p> <code>agent_redis_host</code> <code>str</code> <p>Redis host address for agent (may differ from main Redis). Defaults to <code>localhost</code>.</p> <code>agent_redis_port</code> <code>int</code> <p>Redis port number for agent. Defaults to <code>6379</code>.</p> <code>minio_endpoint</code> <code>str</code> <p>MinIO server endpoint address. Defaults to <code>localhost</code>.</p> <code>minio_access_key</code> <code>str</code> <p>MinIO access key for authentication. Defaults to <code>minioadmin</code>.</p> <code>minio_secret_key</code> <code>str</code> <p>MinIO secret key for authentication. Defaults to <code>minioadmin</code>.</p>"},{"location":"configuration/#rhea.server.schema.Settings.model_config","title":"<code>model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8', extra='ignore')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.host","title":"<code>host: str = 'localhost'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.port","title":"<code>port: int = 3001</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.debug_port","title":"<code>debug_port: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.database_url","title":"<code>database_url: str = 'postgresql+asyncpg://postgres:postgres@localhost:5432/rhea'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.client_ttl","title":"<code>client_ttl: int = 3600</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_container_backend","title":"<code>parsl_container_backend: Literal['docker', 'podman'] = 'docker'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_container_network","title":"<code>parsl_container_network: Literal['host', 'local'] = 'host'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_container_debug","title":"<code>parsl_container_debug: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_max_workers_per_node","title":"<code>parsl_max_workers_per_node: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_provider","title":"<code>parsl_provider: Literal['local', 'pbs', 'k8'] = 'local'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_init_blocks","title":"<code>parsl_init_blocks: int = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_min_blocks","title":"<code>parsl_min_blocks: int = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_max_blocks","title":"<code>parsl_max_blocks: int = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_nodes_per_block","title":"<code>parsl_nodes_per_block: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.parsl_parallelism","title":"<code>parsl_parallelism: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.agent_handle_timeout","title":"<code>agent_handle_timeout: int = 30</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.redis_host","title":"<code>redis_host: str = 'localhost'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.redis_port","title":"<code>redis_port: int = 6379</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.embedding_url","title":"<code>embedding_url: str = 'http://localhost:8000/v1'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.embedding_key","title":"<code>embedding_key: str = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.model","title":"<code>model: str = 'Qwen/Qwen3-Embedding-0.6B'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.agent_redis_host","title":"<code>agent_redis_host: str = 'localhost'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.agent_redis_port","title":"<code>agent_redis_port: int = 6379</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.minio_endpoint","title":"<code>minio_endpoint: str = 'localhost'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.minio_access_key","title":"<code>minio_access_key: str = 'minioadmin'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.Settings.minio_secret_key","title":"<code>minio_secret_key: str = 'minioadmin'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings","title":"<code>PBSSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Configuration settings for PBS (Portable Batch System) execution provider.</p> <p>Attributes:</p> Name Type Description <code>account</code> <code>str</code> <p>PBS account name for job submission.</p> <code>queue</code> <code>str</code> <p>PBS queue name to submit jobs to.</p> <code>walltime</code> <code>str</code> <p>Maximum wall clock time for PBS jobs.</p> <code>scheduler_options</code> <code>str</code> <p>Additional PBS scheduler options.</p> <code>select_options</code> <code>str</code> <p>PBS select statement options for resource specification.</p> <code>worker_init</code> <code>str</code> <p>Commands to run before workers are launched. Defaults to empty string.</p> <code>cpus_per_node</code> <code>int</code> <p>Number of hardware threads per node. Defaults to <code>1</code>.</p>"},{"location":"configuration/#rhea.server.schema.PBSSettings.model_config","title":"<code>model_config = SettingsConfigDict(env_file='.env_pbs', env_file_encoding='utf-8')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.account","title":"<code>account: str</code>  <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.queue","title":"<code>queue: str</code>  <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.walltime","title":"<code>walltime: str</code>  <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.scheduler_options","title":"<code>scheduler_options: str</code>  <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.select_options","title":"<code>select_options: str</code>  <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.worker_init","title":"<code>worker_init: str = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.PBSSettings.cpus_per_node","title":"<code>cpus_per_node: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.K8Settings","title":"<code>K8Settings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Configuration settings for Kubernetes (K8s) execution provider.</p> <p>Attributes:</p> Name Type Description <code>namespace</code> <code>str</code> <p>Kubernetes namespace for pod deployment. Defaults to <code>rhea</code>.</p> <code>max_cpu</code> <code>float</code> <p>Maximum CPU limit for pods. Defaults to <code>2.0</code>.</p> <code>max_mem</code> <code>str</code> <p>Maximum memory limit for pods. Defaults to <code>2048Mi</code>.</p> <code>request_cpu</code> <code>float</code> <p>CPU request for pods. Defaults to <code>1.0</code>.</p> <code>request_mem</code> <code>str</code> <p>Memory request for pods. Defaults to <code>1024Mi</code>.</p>"},{"location":"configuration/#rhea.server.schema.K8Settings.model_config","title":"<code>model_config = SettingsConfigDict(env_file='.env_k8', env_file_encoding='utf-8')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.K8Settings.namespace","title":"<code>namespace: str = 'rhea'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.K8Settings.max_cpu","title":"<code>max_cpu: float = 2.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.K8Settings.max_mem","title":"<code>max_mem: str = '2048Mi'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.K8Settings.request_cpu","title":"<code>request_cpu: float = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"configuration/#rhea.server.schema.K8Settings.request_mem","title":"<code>request_mem: str = '1024Mi'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"deploy/","title":"Deploying Rhea","text":""},{"location":"deploy/#docker-local","title":"Docker (Local)","text":"<pre><code>docker compose -f deploy/docker-compose.yaml up -d\n</code></pre> <p>With GPU support (for embedding model):</p> <pre><code>docker compose -f deploy/docker-compose.gpu.yaml -d\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Rhea is a MCP-compliant server that can be used across a variety of LLM clients and libraries to perform dynamic discovery and execution of thousands of tools. While all MCP functionality can be performed with any MCP-compatible client libary, we provide a client libary to provide a simple interface with Rhea's tool workflow and file management.</p> <p>The client can be installed from PyPI using the <code>uv</code> package manager:</p> <pre><code>uv add rhea-mcp\n</code></pre> <p>Or with <code>pip</code>:</p> <pre><code>pip install rhea-mcp\n</code></pre>"},{"location":"examples/#tool-calling","title":"Tool Calling","text":"<p>Tool calling with Rhea is performed exclusively over the MCP protocol to provide universal support across many LLM clients. The Rhea client library provides several helper functions on-top of the FastMCP client libary for ease of use.</p>"},{"location":"examples/#finding-tools","title":"Finding Tools","text":"<p>A major feature of Rhea is the ability to dynamically propogate the tools made available on the server via Retrieval Augmented Generation (RAG). This is achieved by providing a natural language query to the <code>find_tools()</code> MCP tool which will perform a server-side RAG and populate the tools for this client session.</p>"},{"location":"examples/#using-rhea-client-library","title":"Using Rhea Client Library","text":"<p>The following script accepts a natural language query, such as \"I need a tool to convert FASTA to FASTQ\", and returns the relevant tools for this query.</p> <p>This script can be found in examples/find_tools.py</p> <pre><code># find_tools.py\n\nimport asyncio\nfrom rhea.client import RheaClient\nfrom argparse import ArgumentParser\nfrom urllib.parse import urlparse\nfrom mcp.types import Tool\n\nparser = ArgumentParser(\n    description=\"Find relevant tools based on natural language query.\"\n)\nparser.add_argument(\"query\", help=\"Natural language query\")\nparser.add_argument(\"--url\", help=\"URL of MCP server\", default=\"http://localhost:3001\")\n\nargs = parser.parse_args()\n\n\nasync def main():\n    parsed_url = urlparse(args.url)\n    protocol = parsed_url.scheme\n    host = parsed_url.hostname\n    port = parsed_url.port\n    secure = protocol == \"https\"\n\n    async with RheaClient(host, port, secure) as client:  # (1)!\n        await client.find_tools(args.query)  # (2)!\n        tools: list[Tool] = await client.list_tools()  # (3)!\n        print(tools)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())  # (4)!\n</code></pre> <ol> <li>Open a connection with the MCP server with an asynchronous context manager.</li> <li>Call <code>find_tools()</code> with a natural language query string.</li> <li>List the tools avaiable on the server for this client.</li> <li>Make sure to run as a coroutine.</li> </ol>"},{"location":"examples/#using-fastmcp","title":"Using FastMCP","text":"<pre><code>import asyncio\nfrom argparse import ArgumentParser\nfrom mcp import ClientSession\nfrom mcp.client.streamable_http import streamablehttp_client\nfrom mcp.types import Tool\n\nparser = ArgumentParser(\n    description=\"Find relevant tools based on natural language query.\"\n)\nparser.add_argument(\"query\", help=\"Natural language query\")\nparser.add_argument(\"--url\", help=\"URL of MCP server\", default=\"http://localhost:3001\")\n\nargs = parser.parse_args()\n\nasync def main():\n    async with streamablehttp_client(f\"{args.url}/mcp\") as (\n        read,\n        write,\n        get_session_id_callback,\n    ):\n        async with ClientSession(read, write) as session:\n            await session.initialize()\n            await http_client_session.call_tool(\n                \"find_tools\", {\"query\": \"I need a tool to convert FASTA to FASTQ\"}\n            )\n            tools: list[Tool] = await client.list_tools()\n            print(tools)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/#file-management","title":"File Management","text":"<p>For many tools, you will need to manage input and output files for your tool calls. To assist with file management, the Rhea server exposes a REST API that allows for file uploads/downloads to the backend server.</p> <p>Files stored within Rhea are keyed as UUIDv4 strings and are accepted as input for tool calls requiring input files. </p>"},{"location":"examples/#uploading-a-file","title":"Uploading a File","text":"<p>The following script lets you upload a file from your local directory to the Rhea MCP server. </p> <p>The script will output a UUIDv4 string representing the file string.</p> <p>This script can be found in examples/upload_file.py</p> <pre><code># upload_file.py\n\nimport asyncio\nfrom rhea.client import RheaClient\nfrom argparse import ArgumentParser\nfrom urllib.parse import urlparse\n\nparser = ArgumentParser(description=\"Upload files to Rhea MCP server\")\nparser.add_argument(\"input_file\", help=\"Input file\")\nparser.add_argument(\"--url\", help=\"URL of MCP server\", default=\"http://localhost:3001\")\nparser.add_argument(\"--name\", required=False, help=\"Name for uploaded file.\")\n\nargs = parser.parse_args()\n\n\nasync def main():\n    parsed_url = urlparse(args.url)\n    protocol = parsed_url.scheme\n    host = parsed_url.hostname\n    port = parsed_url.port\n    secure = protocol == \"https\"\n\n    async with RheaClient(host, port, secure) as client:  # (1)!\n        result: dict = await client.upload_file(args.input_file, args.name)  # (2)!\n        print(result)\n        print(result[\"key\"])  # (3)!\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())  # (4)!\n</code></pre> <ol> <li>Open a connection with the MCP server with an asynchronous context manager.</li> <li>Call <code>upload_file()</code> with the path of your file.</li> <li>This is the file key for your uploaded file to be used as input for tools.</li> <li>Make sure to run as a coroutine.</li> </ol> <p>Usage: <pre><code>python upload_file.py /path/to/file --url http://localhost:3001\n</code></pre></p>"},{"location":"examples/#downloading-a-file","title":"Downloading a File","text":"<p>The following scripts lets you download a file from the Rhea MCP server to a local directory.</p> <p>This script can be found in examples/download_file.py</p> <pre><code># download_file.py\n\nimport asyncio\nfrom rhea.client import RheaClient\nfrom argparse import ArgumentParser\nfrom pathlib import Path\nfrom urllib.parse import urlparse\n\nparser = ArgumentParser(description=\"Download files from Rhea MCP server\")\nparser.add_argument(\"key\", help=\"Key of desired file\")\nparser.add_argument(\"--url\", help=\"URL of MCP server\", default=\"http://localhost:3001\")\nparser.add_argument(\"--output-directory\", help=\"Output directory\", default=Path.cwd())\nparser.add_argument(\"--output-name\", help=\"Name of output file\")\n\nargs = parser.parse_args()\n\n\nasync def main():\n    parsed_url = urlparse(args.url)\n    protocol = parsed_url.scheme\n    host = parsed_url.hostname\n    port = parsed_url.port\n    secure = protocol == \"https\"\n\n    async with RheaClient(host, port, secure) as client:  # (1)!\n        await client.download_file(args.key, args.output_directory)  # (2)!\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())  # (3)!\n</code></pre> <ol> <li>Open a connection with the MCP server with an asynchronous context manager. </li> <li>Call <code>download_file()</code> with your desired file key and output path.</li> <li>Make sure to run as a coroutine.</li> </ol> <p>Usage: <pre><code>python download_file.py file_key /path/to/output/directory\n</code></pre></p>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#architecture","title":"Architecture","text":""},{"location":"overview/#protocol","title":"Protocol","text":"<pre><code>sequenceDiagram\nparticipant Client as Client\nparticipant Server as Server\n\nNote over Client, Server: Initialization\nClient-&gt;&gt;Server: Call tools/list\nServer-&gt;&gt;Client: Return find_tools()\n\nloop Agent Loop\nNote over Client, Server: Perform Tool Discovery (RAG)\nClient-&gt;&gt;Server: Call find_tools(query)\nServer--&gt;&gt;Client: Notify tools/list_changed\nClient-&gt;&gt;Server: Get tools/list\nServer--&gt;&gt;Client: List of tools\n\n\nNote over Client, Server: Call Tool\nClient-&gt;&gt;Server: Call Tool echo('hello')\nServer--&gt;&gt;Client: Tool Progress (0%)\nServer--&gt;&gt;Client: Tool Progress (100%)\nServer-&gt;&gt;Client: Return result for Tool echo('hello')\n\nend\n</code></pre>"}]}